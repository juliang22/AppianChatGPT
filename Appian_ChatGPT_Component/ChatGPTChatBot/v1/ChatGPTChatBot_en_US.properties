name=ChatGPTChatBot
description=ChatBot interface for OpenAI ChatGPT
parameter.openAIConnectedSystem.name=openAIConnectedSystem
parameter.openAIConnectedSystem.description=(Required) Constant referencing OpenAI Connected System.
parameter.systemMessage.name=System Message
parameter.systemMessage.description=(Optional - Defaults to "You are a helpful assistant.") The system message helps set the behavior of the assistant. 
parameter.initialMessage.name=Initial Message
parameter.initialMessage.description=(Optional - Defaults to "Hi, I'm AppianGPT. How can I help you?") Initial message shown to the user from the AI. This will be the beginning of the chat conversation.
parameter.model.name=Model
parameter.model.description=(Optional - Defaults to gpt-3.5-turbo) ID of the model to use. Currently, only gpt-3.5-turbo and gpt-3.5-turbo-0301 are supported.
parameter.temperature.name=Temperature
parameter.temperature.description=(Optional - Defaults to 1). What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. It is generally recommended to alter this or top_p, but not both.
parameter.top_p.name=Top_p
parameter.top_p.description=(Optional - Defaults to 1) An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommended to alter this or temperature, but not both.
parameter.n.name=N
parameter.n.description=(Optional - Defaults to 1) How many chat completion choices to generate for each input message.
parameter.stop.name=Stop
parameter.stop.description=(Optional - Defaults to null)  Up to 4 sequences where the API will stop generating further tokens.
parameter.max_tokens.name=Max_tokens
parameter.max_tokens.description=(Optional - defaults to inf) The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens).
parameter.presence_penalty.name=Presence_penalty
parameter.presence_penalty.description=(Optional - Defaults to 0) Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
parameter.frequency_penalty.name=Frequency_penalty
parameter.frequency_penalty.description=(Optional - Defaults to 0) Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
parameter.user.name=User
parameter.user.description=(Optional - Defaults to null) A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
parameter.style.name=Style
parameter.style.description=Customized styling for the component's title, text, and chat. Default properties are set to     style: {titleText: "Appian Assistant",titleTextColor: "#FBFBFB",titleBackgroundColor: "#010A50",GPTTextColor: "#332D2D",GPTChatColor: "#f5f6f7", userTextColor: "#FBFBFB", userChatColor: "#2621F6", sendButtonColor: "#2621F6",}. GPTIcon and userIcon can also be set by providing     style: {GPTIcon: document(documentId: cons!G_IMAGE, property: "url") }    where cons!G_IMAGE is a constant of an image in Appian.
parameter.chatHeight.name=Chat Height
parameter.chatHeight.description=(Optional - Defaults to 500px, minimum is 300px) Set the height of the chat component. Use this parameter to control height rather than the OOTB height field.
parameter.SAILGen.name=Sail Generation
parameter.SAILGen.description=Generated SAIL code
parameter.conversation.name=Conversation
parameter.conversation.description=The history of all messages in the conversation, starting with systemMessage and initialMessage.
parameter.demoType.name=Demo version
parameter.demoType.description=What demo to run
parameter.recordQuery.name=Record Query
parameter.recordQuery.description=Finished record query to transform from natural language query generated by LLM to uuid query that can be executed